\input{../Preambulos/pre_documento}
\input{../Preambulos/pre_plantilla_Warsaw_crane}
\input{../Preambulos/pre_codigo}
\input{../Preambulos/pre_define_footers_Warsaw_crane}	
\normalfont
\usepackage{ccfonts}% http://ctan.org/pkg/{ccfonts}
\usepackage[T1]{fontenc}% http://ctan.or/pkg/fontenc
\renewcommand{\rmdefault}{cmr}% cmr = Computer Modern Roman
\linespread{1.3}
\title{Métodos numéricos para matrices}
\subtitle{Curso de Física Computacional}
\author{M. en C. Gustavo Contreras Mayén}
\date{\today}
\institute{Facultad de Ciencias - UNAM}
\titlegraphic{\includegraphics[width=1.75cm]{Imagenes/escudo-facultad-ciencias}\hspace*{4.75cm}~%
   \includegraphics[width=1.75cm]{Imagenes/escudo-unam}
}
\begin{document}
\maketitle
\fontsize{14}{14}\selectfont
\spanishdecimal{.}
\section*{Contenido}
\frame{\tableofcontents[currentsection, hideallsubsections]}
\section{Introducción}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Primer ejemplo: Vibraciones en una molécula}
\begin{frame}
\frametitle{Primer ejemplo: Vibraciones en una molécula}
Supongamos que queremos estudiar el espectro de vibraciones de una molécula con $n$ grados de libertad.
\end{frame}
\begin{frame}
\frametitle{Primera aproximación}
La primera aproximación consiste en investigar las oscilaciones armónicas del sistema, expandiendo la energía potencial hasta el segundo orden en las coordenadas generalizadas alrededor de las posiciones de equilibrio:
\pause
\[ U(q_{1}, q_{2}, \ldots, q_{n}) \simeq \dfrac{1}{2} \sum_{i, j = 1} A_{ij} \: q_{i} \: q_{j}\]
\end{frame}
\begin{frame}
\frametitle{Energía potencial}
\[ U(q_{1}, q_{2}, \ldots, q_{n}) \simeq \dfrac{1}{2} \sum_{i,j=1} A_{ij} \: q_{i} \: q_{j}\]
donde $q_{i}$ son las coordenadas generalizadas y $A_{jk}$ son parámetros del potencial que usualmente pueden obtenerse a partir de un cálculo de química cuántica.
\end{frame}
\begin{frame}
\frametitle{Energía cinética}
La energía cinética puede escribirse en términos de las velocidades generalizadas.
\[ T(\dot{q_{1}}, \dot{q_{2}}, \ldots, \dot{q_{n}}) \simeq \dfrac{1}{2} \sum_{i, j=1} M_{ij} \: \dot{q_{i}} \: \dot{q_{j}} \]
donde las $\dot{q}_{i}= dq_{i}/dt$ son las velocidades generalizadas, las $M_{ij}$ son los elementos de masa generalizado en la matriz, cuyos valores dependen en particular de la molécula. 
\end{frame}
\begin{frame}
\frametitle{El Lagrangiano}
Aplicando la ecuación de Lagrange
\[ \dfrac{\partial \mathcal{L}}{\partial q_i} - \dfrac{d}{dt} \: \dfrac{\partial \mathcal{L}}{\partial \dot{q_{i}}} = 0 \]
donde el lagrangiano del sistema es: $\mathcal{L} = T - U$, por tanto, tenemos que:
\[ \sum_{j = 1}^{n} \left( A_{ij} \: q_{j} + M_{ij} \: \ddot{q_{j}} \right) = 0, \hspace{1cm} i = 1, 2, \ldots, n \]
\end{frame}
\begin{frame}
\frametitle{Dependencia del tiempo de tipo oscilatorio }
Si suponemos que la dependencia del tiempo en las coordenadas generalizadas es de tipo oscilatorio, con
\[ q_{j} = x_{j} \: e^{-i \omega t} \]
Se obtiene el siguiente sistema de ecuaciones homogéneo:
\[ \sum_{j = 1}^{n} \left( A_{ij} -  \omega^{2} \: M_{ij} \right) x_{j} = 0, \hspace{1cm} i = 1, 2, \ldots, n \]
\end{frame}
\begin{frame}
\frametitle{Expresión matricial}
La ecuación anterior se puede re-escribir en forma matricial, como.
\[ \begin{pmatrix}
A_{11} & \ldots & A_{1n} \\
\vdots & \vdots & \vdots \\
A_{n1} & \ldots & A_{nn}
\end{pmatrix}
\begin{pmatrix}
x_{1} \\
\vdots \\
x_{n}
\end{pmatrix} = \lambda
\begin{pmatrix}
M_{11} & \ldots & M_{1n} \\
\vdots & \vdots & \vdots \\
M_{n1} & \ldots & M_{nn}
\end{pmatrix}
\begin{pmatrix}
x_{1} \\
\vdots \\
x_{n}
\end{pmatrix}
\]
\end{frame}
\begin{frame}
\frametitle{Expresión reducida}
De manera equivalente
\[ \mathbf{A \: x} = \lambda \: \mathbf{M \: x} \]
donde $\lambda= \omega^{2}$ es el valor propio y $\mathbf{x}$ es el correspondiente vector propio de la ecuación de valores propios.\\
\end{frame}
\begin{frame}
\frametitle{Solución no trivial del sistema}
Este es un sistema de ecuaciones lineales homogéneas; con el fin de contar con una solución no trivial del conjunto de ecuaciones, el determinante de la matriz de coeficientes debe anularse, esto es
\[ det \vert \mathbf{A} - \lambda \: \mathbf{M} \vert = 0  \]
\end{frame}
\begin{frame}
\frametitle{Raíces de la ecuación matricial}
\[ det \vert \mathbf{A} - \lambda \: \mathbf{M} \vert = 0  \]
Las raíces de esta ecuación $\lambda_{k}$ con $k = 1, 2, \ldots, n$ proporcionan todas las frecuencias angulares vibracionales de la molécula
\[ \omega_{k} = \sqrt{\lambda_{k}}\]
\end{frame}
\subsection{Segundo ejemplo: Circuito eléctrico}
\begin{frame}[fragile]
\frametitle{Segundo ejemplo: Circuito eléctrico}
Consideremos el siguiente circuito eléctrico:
\begin{figure}
	\centering
	\includestandalone{Figuras/circuito_electrico_01}
\end{figure}
\end{frame}
\begin{frame}
\frametitle{Solución para el circuito}
Podemos aplicar las leyes de Kirchhoff para obtener un conjunto de ecuaciones que relacionan los voltajes y las corrientes del circuito, luego entonces, resolverlo y encontrar las incógnitas.
\end{frame}
\begin{frame}
\frametitle{Solución para el circuito}
Pero ahora veamos el caso del puente desbalanceado de Wheastone: tenemos tres circuitos (o mallas) independientes:
\end{frame}
\begin{frame}[fragile]
\frametitle{Circuito/Malla independiente 1}
\begin{figure}
	\centering
	\includestandalone{Figuras/circuito_electrico_02}
\end{figure}
\[ r_{s} \: i_{1} + r_{1} \: i_{2} + r_{2} \: i_{3} = v_{0}\]
\end{frame}
\begin{frame}[fragile]
\frametitle{Circuito/Malla independiente 2}
\begin{figure}
	\centering
	\includestandalone{Figuras/circuito_electrico_03}
\end{figure}
\[ -r_{x} \: i_{1} + ( r_{1} + r_{x} + r_{a}) \: i_{2} + r_{a} \: i_{3} = 0\]
\end{frame}
\begin{frame}[fragile]
\frametitle{Circuito/Malla independiente 3}
\begin{figure}
	\centering
	\includestandalone{Figuras/circuito_electrico_04}
\end{figure}
\[ -r_{3} \: i_{1} - r_{a} \: i_{2} + ( r_{2} + r_{3} + r_{a}) \: i_{3} = 0\]
\end{frame}
\begin{frame}
\frametitle{Sistema de ecuaciones}
Entonces el sistema de ecuaciones resulta ser:
\begin{align*}
r_{s} \: i_{1} + r_{1} \: i_{2} + r_{2} \: i_{3} &= v_{0} \\
-r_{x} \: i_{1} + (r_{1} + r_{x} + r_{a}) \: i_{2} + r_{a} \: i_{3} &= 0 \\
-r_{3} \: i_{1} - r_{a} \: i_{2} + (r_{2} + r_{3} + r_{a}) \: i_{3} &= 0
\end{align*}
\pause
El sistema anterior se puede escribir como
\[ \mathbf{R \: i} = \mathbf{v}\]
\end{frame}
\begin{frame}
\frametitle{Descripción del sistema}
\[ \mathbf{R \: i} = \mathbf{v}\]
donde la matriz de coeficientes de las resistencias es
\[\mathbf{R} =
\begin{pmatrix}
r_{s} & r_{1} & r_{2} \\
-r_{x} & r_{1} + r_{x} + r_{a} & -r_{a} \\
-r_{3} & -r_{a} & r_{2} + r_{3} + r_{a}
\end{pmatrix} \]
\end{frame}
\begin{frame}
\frametitle{Descripción del sistema}
Los vectores columna de corrientes y voltajes son:
\[ \mathbf{i} =
\begin{pmatrix}
i_{1} \\
i_{2} \\
i_{3}
\end{pmatrix}
\hspace{2cm}
\mathbf{v} =
\begin{pmatrix}
v_{0} \\
0 \\
0
\end{pmatrix} \]
\end{frame}
\begin{frame}
\frametitle{Solución del sistema matricial}
Multiplicando en ambos lados por $\mathbf{R}^{-1}$ (la matriz inversa de $\mathbf{R}$), la ecuación
\[ \mathbf{Ri} = \mathbf{v}\]
resulta
\[ \mathbf{i} = \mathbf{R}^{-1}\mathbf{v}\]
pero se requiere que conozcamos $\mathbf{R}^{-1}$.
\\
\bigskip
\pause
¿Será necesario conocer siempre la matriz inversa?
\end{frame}
\section{Sistemas lineales algebraicos}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection*{Sistemas lineales con la computadora}
\begin{frame}
\frametitle{Sistemas lineales algebraicos}
En este tema analizamos la solución de sistemas de ecuaciones lineales algebraicos, con $n$ incógnitas. 
\end{frame}
\begin{frame}
\frametitle{Sistemas lineales algebraicos}
Cuando tomamos un problema físico, los conjuntos de ecuaciones a menudo son muy grandes, por lo que consumen una gran cantidad de recursos computacionales.
\end{frame}
\subsection*{Uso de propiedades de la matriz}
\begin{frame}
\frametitle{Uso de propiedades de la matriz}
Por lo general, se reducen los requerimientos de almacenamiento y el tiempo de ejecución mediante el aprovechamiento de propiedades especiales de la matriz de coeficientes, tales como poca densidad (la mayoría de los elementos de un matriz dispersa son cero -las llamadas matrices \textit{sparse}-)
\end{frame}
\subsection*{Algoritmos de solución}
\begin{frame}
\frametitle{Algoritmos específicos de solución}
Existen muchos algoritmos dedicados a la solución de grandes conjuntos de ecuaciones, cada uno de ellos está adaptado a una determinada forma del coeficiente de la matriz (simétrica, de bandas, escaso, etc.)
\end{frame}
\begin{frame}
\frametitle{Librerías de algoritmos}
En internet se encuentran disponibles librerías para resolver cierto tipo de problemas, al usarlas se requiere conocer la manera en que se proporcionan los argumentos y las variables de resultado que proporcionan, se obliga la revisión de la documentación de cada uno de los códigos.
\end{frame}
\subsection{Sistema algebraico}
\begin{frame}
\frametitle{Definición de sistema algebraico}
Un sistema algebraico tiene la forma
\[ \begin{split}
A_{11} x_{1} + A_{12} x_{2} + \ldots + A_{1n} x_{n} &= b_{1} \\
A_{21} x_{1} + A_{22} x_{2} + \ldots + A_{2n} x_{n} &= b_{2} \\
 &= \vdots \\
A_{n1} x_{1} + A_{n2} x_{2} + \ldots + A_{nn} x_{n} &= b_{n} \\
\end{split} \]
o sencillamente
\[ \mathbf{A \: x} = \mathbf{b} \]
\end{frame}
\begin{frame}[fragile]
\frametitle{Matriz aumentada}
Una representación particularmente útil de las ecuaciones para los propósitos computacionales es la \emph{matriz de coeficientes aumentada}, que se obtiene al juntar el vector constante $b$ a la matriz de coeficientes $A$ de la siguiente manera:
\end{frame}
\begin{frame}[fragile]
\frametitle{Matriz aumentada}
\begin{equation*}
\left[ A \vert b \right] = \left[
\begin{tabular}{c c c c | c}
$A_{11}$ & $A_{12}$ & $\ldots$ & $A_{1n}$ & $b_{1}$ \\
$A_{21}$ & $A_{22}$ & $\ldots$ & $A_{2n}$ & $b_{2}$ \\
$\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ & $\vdots$ \\
$A_{n1}$ & $A_{n2}$ & $\ldots$ & $A_{nn}$ & $b_{n}$ 
\end{tabular}
\right]
\end{equation*} 
\end{frame}
\subsection{Unicidad de la solución}
\begin{frame}
\frametitle{Unicidad de la solución}
Un sistema de $n$ ecuaciones lineales con $n$ incógnitas tiene una solución única, siempre que el determinante de la matriz de coeficientes sea \textcolor{red}{no singular}, es decir, $\vert A \vert = 0$. 
\end{frame}
\begin{frame}
\frametitle{Unicidad de la solución}
Las filas y columnas de una matriz no singular son linealmente independientes en el sentido de que no hay ninguna fila (o columna) que sea una combinación lineal de las otras filas (o columnas)
\end{frame}
\begin{frame}
\frametitle{Soluciones infinitas}
Si la matriz de coeficientes es singular, las ecuaciones pueden tener un número infinito de soluciones o no soluciones en absoluto, dependiendo del vector constante.
\end{frame}
\subsection*{Caso 1: Soluciones infinitas}
\begin{frame}
\frametitle{Caso 1}
Como ejemplo veamos las ecuaciones
\begin{align*}
2x + y &= 3 \\
4x + 2y &= 6
\end{align*}
\pause
La segunda ecuación puede obtenerse multiplicando la primera ecuación por dos.
\end{frame}
\begin{frame}
\frametitle{Caso 1}
Cualquier combinación de $x$ e $y$ que satisface la primera ecuación es también una solución de la segunda.
\\
\bigskip
El número de tales combinaciones es infinito.
\end{frame}
\begin{frame}
\frametitle{Las dos rectas se superponen}
\begin{figure}
	\centering
	\includegraphics[scale=0.4]{Imagenes/Grafica01.eps}
	\caption{Representación gráfica cuando la matriz de coeficientes es singular.}
\end{figure}
\end{frame}
\subsection*{Caso 2: Sistemas sin solución}
\begin{frame}
\frametitle{Caso 2}
En otro caso, las ecuaciones
\begin{align*}
2 \: x + y &= 3 \\
4 \: x + 2 \:y &= 0
\end{align*}
No tienen solución, ya que la ecuación equivalente $2 \: x + y = 0$, contradice la primera.
\\
\bigskip
\pause
Por tanto, cualquier solución que satisface la primera, no puede satisfacer la segunda.
\end{frame}
\begin{frame}
\frametitle{Las dos rectas son paralelas}
\begin{figure}
	\centering
	\includegraphics[scale=0.4]{Imagenes/Grafica02.eps}
	\caption{Representación gráfica de un sistema algebraico sin solución.}
\end{figure}
\end{frame}
\subsection{Problemas mal condicionados}
\begin{frame}
\frametitle{Problemas mal condicionados}
Una pregunta obvia es: ¿qué sucede cuando la matriz de coeficientes es casi singular? es decir, si $\vert A \vert$ es muy pequeño?
\end{frame}
\begin{frame}
\frametitle{Problemas mal condicionados}
Con el fin de concluir si el determinante de la matriz es pequeño, necesitamos una referencia contra la cual el  determinante se pueda medir.
\end{frame}
\subsection*{Norma de una matriz}
\begin{frame}
\frametitle{Norma de una matriz}
Esta referencia se denomina la \textcolor{blue}{norma de la matriz} y se denota por $\parallel A \parallel$.
\\
\bigskip
Entonces podemos decir que el determinante es pequeño si
\[ \vert A \vert << \parallel A \parallel \]
\end{frame}
\begin{frame}
\frametitle{Definición de la norma de una matriz}
Existen diferentes maneras de calcular la norma de una matriz, tales como
\begin{align*}
\parallel A \parallel =& \sqrt{\sum_{i = 1}^{n} \: \sum_{j = 1}^{n} \:  A^{2}_{ij}} \\
\parallel A \parallel =& \max\limits_{1 \leq i \leq j} \sum_{j=1}^{n} \: \vert A_{ij} \vert
\end{align*}
\end{frame}
\subsection{Número de condición de la matriz}
\begin{frame}
\frametitle{Número de condición de la matriz}
Una medida formal de condicionamiento está dada por el \textcolor{blue}{número de condición de la matriz}, definido por:
\[ \mbox{cond}(A) = \parallel A \parallel \parallel A^{-1} \parallel   \]
Si este número es cercano a la unidad, la matriz está bien condicionada.
\end{frame}
\begin{frame}
\frametitle{Número de condición de la matriz}
El número de condición aumenta con el grado de mal acondicionamiento, tendiendo a infinito para una matriz singular.
\\
\bigskip
Toma en cuenta que el número de condición no es único, sino que depende de la elección de la norma de la matriz.
\end{frame}
\begin{frame}
\frametitle{Número de condición de la matriz}
Desafortunadamente, el número de condición es costoso de calcular para grandes matrices.
\\
\bigskip
En la mayoría de los casos es suficiente para medir el condicionamiento comparando el determinante con las magnitudes de los elementos en la matriz.
\end{frame}
% \begin{frame}
% \frametitle{Uso de las librerías numpy y scipy}
% Aquí va la parte de manejo del álgebra matricial con \python{}
% \end{frame}
\subsection*{Efectos del mal condicionamiento}
\begin{frame}
\frametitle{Efectos del mal condicionamiento}
Si las ecuaciones están mal condicionadas, pequeños cambios en la matriz de coeficientes dan como resultado grandes cambios en la solución.
\end{frame}
\begin{frame}
\frametitle{Efectos del mal condicionamiento}
A modo de ejemplo, consideremos las ecuaciones:
\begin{align*}
2 \: x + y &= 3 \\
2 \: x + 1.001 \:y &= 0
\end{align*}
que tiene la solución $x = 1501.5$, $y = -3000$
\end{frame}
\begin{frame}[fragile]
\frametitle{La norma es menor que los coeficientes}
Dado que 
\[ \vert A \vert = 2 \: (1.001) - 2 \: (1) = 0.002 \]
 es mucho menor que los coeficientes, las ecuaciones están mal condicionadas.
\\
\bigskip
\pause
Usemos arreglos y las funciones de \python{} para explorar este sistema.
\end{frame}
\subsection*{Representación de las matrices}
\begin{frame}
\frametitle{Representación de las matrices}
El sistema de ecuaciones algebraicas
\begin{align*}
2 \: x + y &= 3 \\
2 \: x + 1.001 \:y &= 0
\end{align*}
Se va a representar de la siguiente forma:
\end{frame}
\begin{frame}
\frametitle{Matrices $\mathbf{A \: x =  b}$}
\begin{align*}
\mathbf{A} = \begin{pmatrix}
2 & 1 \\
2 & 1.001
\end{pmatrix}
\hspace{2cm}
\mathbf{b} = \begin{pmatrix}
3 \\
0
\end{pmatrix}
\end{align*}
\end{frame}
\subsection*{El objeto array}
\begin{frame}
\frametitle{El objeto \funcionazul{array}}
El objeto que debemos de utilizar es el \funcionazul{array}, ya que es la manera con la que podremos aprovechar las funciones de \python{}.
\end{frame}
\begin{frame}
\frametitle{El objeto \funcionazul{array}}
Nótese que la manera en que se ingresan los elementos del arreglo en \python{}, es por renglones, en otros lenguajes de programación o programas, los elementos se pueden ingresar por columnas, siendo necesario revisar la documentación respectiva.
\end{frame}
\begin{frame}[fragile]
\frametitle{El objeto \funcionazul{array}}    
\begin{align*}
\mathbf{A} = \begin{pmatrix}
2 & 1 \\
2 & 1.001
\end{pmatrix}
\end{align*}
\vspace{1cm}
\begin{verbatim}
A = array([[2., 1.], [2, 1.001]])
\end{verbatim}
\end{frame}
\subsection*{Funciones en linalg}
\begin{frame}
\frametitle{Algunas funciones en \funcionazul{linalg}}
En \funcionazul{numpy.linalg} se tiene un conjunto de funciones útiles para las operaciones entre arreglos (podemos expresar el término \emph{matrices} sin caer en complicaciones), entre otras podemos mencionar:
\end{frame}
\begin{frame}
\frametitle{1. Producto entre matrices y vectores}
\begin{tabular}{l | m{7.5cm}}
Función & Descripción \\ \hline
\funcionazul{dot(a, b)} & Producto punto de dos arreglos. \\ \hline
\funcionazul{vdot(a, b)} & Producto punto de dos vectores. \\ \hline
\end{tabular}
\end{frame}
\begin{frame}
\frametitle{2. Norma y otros valores}
\fontsize{12}{12}\selectfont
\begin{tabular}{l | m{7.5cm}}
Función & Descripción \\ \hline
\funcionazul{norm(x)} & La norma de un arreglo o vector. \\ \hline
\funcionazul{cond(x)} & Calcula el número de condición de una matriz. \\ \hline
\funcionazul{det(a)} & Calcula el determinante de un arreglo. \\ \hline
\funcionazul{matrix\_rank(M)} & Devuelve el rango de un arreglo. \\ \hline
\funcionazul{trace(a)} & Devuelve la suma a lo largo de la(s) diagonal(es) de un arreglo.
\end{tabular}
\end{frame}
\begin{frame}
\frametitle{3. Solución de ecuaciones e inversa}
\begin{tabular}{l | m{7.5cm}}
Función & Descripción \\ \hline
\funcionazul{solve(a, b)} & Resuelve una ecuación matricial lineal o un sistema de ecuaciones escalares. \\ \hline
\funcionazul{inv(a)} & Calcula la inversa de una matriz. \\ \hline
\end{tabular}
\end{frame}
\begin{frame}
\frametitle{Haciendo operaciones}
Para las siguientes operaciones es posible utilizar una terminal de \funcionazul{qtConsole} o si tienes abierto \funcionazul{Spyder}, escribe las instrucciones en la misma ventana de la terminal:
\end{frame}
\begin{frame}[fragile]
\frametitle{Calculando el determinante}
\begin{verbatim}
>>> from numpy import array, linalg
>>> a = array([[2., 1.], [2, 1.001]])
>>> b = array([3., 0.])
\end{verbatim}
\pause
Calculamos el valor del determinante
\begin{verbatim}
>>> print (linalg.det(a))
0.002
\end{verbatim}
\end{frame}
\begin{frame}[fragile]
\frametitle{Número de condición}
Ahora calculamos el valor del número de condición	
\begin{verbatim}
>>> print (linalg.cond(a))
5001.00030004
\end{verbatim}
\end{frame}
\begin{frame}[fragile]
\frametitle{Solución del sistema}
Resolvemos el sistema algebraico
\begin{verbatim}
>>> print (linalg.solve(a,b))
[ 1501.5 -3000. ]
\end{verbatim}
\end{frame}
\begin{frame}[fragile]
\frametitle{El sistema está mal condicionado}
El efecto de los malos acondicionamientos se puede verificar mediante un cambio en la segunda ecuación:
\[  \begin{split}
2x + y &= 3 \\
2x + 1.002y &= 0
\end{split} \]
\end{frame}
\begin{frame}[fragile]
\frametitle{El sistema está mal condicionado}
Creamos un nuevo arreglo $c$:
\begin{verbatim}
>>> c = array([[2.,1.],[2.,1.002]])
\end{verbatim}
\pause
Calculamos el número de condición:
\begin{verbatim}
>>> print (linalg.cond(c))
2501.00060016
\end{verbatim}
\end{frame}
\begin{frame}[fragile]
\frametitle{Resolvemos el sistema}
Usando la función \funcionazul{solve(a, b)}, resolvemos el sistema
\begin{verbatim}
>>> print (linalg.solve(c,b))
[  751.5 -1500. ]
\end{verbatim}
\end{frame}
\begin{frame}
\frametitle{\large{Un pequeño cambio provoca un enorme impacto}}
El resultado es $x = 751.5$, $y = -1500$.
\\
\bigskip
Nótese que un cambio del $0.1\%$ en el coeficiente de $y$ produce un cambio de $100\%$ en la solución!
\end{frame}
\section{Sistemas algebraicos lineales}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Definiciones}
\begin{frame}
\frametitle{Sistemas algebraicos lineales}
Las ecuaciones algebraicas lineales, se presentan en casi todas las ramas del análisis numérico. 
\\
\bigskip
Su aplicación más visible es en el análisis de sistemas lineales: cualquier sistema cuya respuesta es proporcional a la entrada se considera que es lineal.
\end{frame}
\begin{frame}
\frametitle{Sistemas algebraicos lineales}
Los sistemas lineales incluyen estructuras, sólidos, elásticos, flujo de calor, filtraciones de líquidos, campos electromagnéticos, los circuitos eléctricos, etc. 
\\
\bigskip
Si el sistema es discreto, tal como una viga o un circuito eléctrico, entonces su análisis conduce directamente a ecuaciones algebraicas lineales.
\end{frame}
\subsection*{Sistemas algebraicos discretos}
\begin{frame}
\frametitle{Sistemas algebraicos discretos}
Si el sistema es discreto, como en los esfuerzos en una viga o circuito eléctrico, entonces su análisis conduce directamente a ecuaciones algebraicas lineales.
\end{frame}
\begin{frame}
\frametitle{Sistemas algebraicos discretos}
En el caso de una viga estática, por ejemplo, las ecuaciones surgen cuando se describen las condiciones de equilibrio de los soportes.
\\
\bigskip
Las incógnitas $x_{1}, x_{2}, \ldots, x_{n}$ representas las fuerzas en las uniones y las reacciones de soporte, mientras que las constantes $b_{1}, b_{2}, \ldots, b_{n}$ son las cargas externas.    
\end{frame}
\begin{frame}
\frametitle{Cambio a un sistema discreto}
El comportamiento de los sistemas continuos se describen por ecuaciones diferenciales, en lugar de ecuaciones algebraicas.
\\
\bigskip
Sin embargo, como el análisis numérico sólo puede ocuparse de variables discretas, es primero necesario aproximar una ecuación diferencial con un sistema de ecuaciones algebraicas.
\end{frame}
\subsection{Métodos conocidos de solución}
\begin{frame}
\frametitle{Métodos conocidos de solución}
Son conocidos los métodos de diferencias finitas, elementos finitos y métodos de contorno del elemento para el análisis de esta manera.
\end{frame}
\begin{frame}
\frametitle{Métodos conocidos de solución}
Estos métodos utilizan diferentes aproximaciones para conseguir una \textit{discretización}, pero en cada caso la tarea final es el mismo: resolver un sistema (a menudo un sistema muy grande) de ecuaciones lineales algebraicas.
\end{frame}
\subsection*{Expresiones de los sistemas algebraicos}
\begin{frame}
\frametitle{Expresiones de los sistemas algebraicos}
El modelado de sistemas lineales invariablemente da lugar a las ecuaciones de la forma $\mathbf{A \:x} = \mathbf{b}$, donde $\mathbf{b}$ es la entrada y $\mathbf{x}$ representa la respuesta del sistema.
\\
\bigskip
El coeficiente de la matriz $\mathbf{A}$, refleja las características del sistema, es independiente
de la entrada.
\end{frame}
\begin{frame}
\frametitle{Expresiones de los sistemas algebraicos}
En otras palabras, si se cambia la entrada, las ecuaciones tienen que ser resueltas de nuevo con una $\mathbf{b}$ diferente, pero el mismo $\mathbf{A}$. 
\\
\bigskip
Por lo tanto, es deseable tener un algoritmo que resuelva a ecuación la solución de algoritmo que puede gestionar cualquier número de vectores constantes con un mínimo esfuerzo computacional.
\end{frame}
\section{Métodos de solución}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Solución directa o indirecta}
\begin{frame}
\frametitle{Métodos de solución}
Hay dos clases de métodos para resolver sistemas de ecuaciones lineales algebraicas:
\setbeamercolor{item projected}{bg=red!70!black,fg=white}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]	
\item Métodos directos.
\item Métodos indirectos.
\end{enumerate}
\end{frame}
\subsection{Métodos directos}
\begin{frame}
\frametitle{Métodos directos}
La característica común de los métodos directos es que transforman las ecuaciones originales en ecuaciones equivalentes (ecuaciones que tienen la misma solución) que se pueden resolver más fácilmente.
\end{frame}
\subsection*{Operaciones elementales}
\begin{frame}
\frametitle{Operaciones elementales}
La transformación se lleva a cabo por la aplicación de las tres operaciones citadas a continuación. 
\\
\bigskip
Estas \emph{operaciones elementales} no cambian la solución, pero pueden afectar el determinante de la matriz de coeficientes como se indica en el paréntesis.
\end{frame}
\begin{frame}
\frametitle{Operaciones elementales}
\setbeamercolor{item projected}{bg=red!70!black,fg=white}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\item Intercambiar dos ecuaciones (cambia el signo de $\vert A \vert$)
\item Multiplicar una ecuación por una constante distinta de cero (se multiplica $\vert A \vert$ por la misma constante)
\item Multiplicar una ecuación por una constante distinta de cero y luego restarlo de otra ecuación (deja a $\vert A \vert$ sin cambios)
\end{enumerate}
\end{frame}
\subsection{Métodos indirectos}
\begin{frame}
\frametitle{Métodos indirectos}
Los métodos iterativos, o métodos indirectos, comienzan con una suposición de la solución $x$, y luego repetidamente refinan la solución hasta alcanzar un criterio de convergencia.
\end{frame}
\begin{frame}
\frametitle{Métodos indirectos}
Los métodos iterativos son generalmente menos eficientes que sus homólogos directos debido al gran número de iteraciones necesarias.
\\
\bigskip
Pero sí tienen ventajas computacionales importantes si la matriz de coeficientes es muy grande y escasamente pobladas (la mayoría de los coeficientes son cero).
\end{frame}
\section{Tres métodos directos}
\frame{\tableofcontents[currentsection, hideothersubsections]}
\subsection{Uso de matrices \texorpdfstring{$U$}{}, \texorpdfstring{$L$}{}, \texorpdfstring{$I$}{}}
\begin{frame}
\frametitle{Tres métodos directos}
A continuación se enumeran los tres métodos directos más usados, cada uno de los cuales utiliza operaciones elementales para producir su propia manera de resolver ecuaciones.
\end{frame}
\begin{frame}
\frametitle{Tres métodos directos}
\fontsize{12}{12}\selectfont
\begin{tabular}{l l l}
Método & Forma inicial & Forma final \\ \hline
Eliminación de Gauss & $A \: x = b$ & $U\: x = c$ \\
Descomposición LU & $A \: x = b$ & $L\: U\: x = b$ \\
Eliminación Gauss-Jordan & $A \: x = b$ & $I \: x = c$
\end{tabular}
\\
\bigskip
\fontsize{14}{14}\selectfont
Donde $\mathbf{U}$ representa una matriz triangular superior, $\mathbf{L}$ es una matriz triangular inferior e $\mathbf{I}$ es la matriz identidad. 
\end{frame}
\begin{frame}
\frametitle{Tres métodos directos}
Una matriz cuadrada se llama triangular si contiene sólo elementos cero en un lado de la diagonal principal.
\end{frame}
\begin{frame}
\frametitle{Matriz $U$}
Una matriz triangular superior $U$ de $3 \times 3$  tiene la forma
\[ U = \begin{bmatrix}
U_{11} & U_{12} & U_{13} \\
0 & U_{22} & U_{23} \\
0 & 0 & U_{33}
\end{bmatrix} \]
\end{frame}
\begin{frame}
\frametitle{Matrices $L$}
Mientras que una matriz triangular inferior $L$ de $3 \times 3$ es del tipo:
\[ L = \begin{bmatrix}
L_{11} & 0 & 0 \\
L_{21} & L_{22} & 0 \\
L_{31} & L_{32} & L_{33}
\end{bmatrix} \]
\end{frame}
\subsection*{Matrices triangulares}
\begin{frame}
\frametitle{Matrices triangulares}
Las matrices triangulares juegan un papel importante en el álgebra lineal, ya que simplifican muchos cálculos.
\end{frame}
\begin{frame}
\frametitle{Matrices triangulares}
Por ejemplo, consideremos la ecuación $L \: x = c$:
\[ \begin{split}
L_{11} \: x_{1} =& c_{1} \\
L_{21} \: x_{1} + L_{22} \: x_{2} =& c_{2} \\
L_{31} \: x_{1} + L_{32} \: x_{2} + L_{33} \: x_{3} =& c_{3} \\
\vdots
\end{split} \]
\end{frame}
\begin{frame}
\frametitle{Matrices triangulares}
Si se resuelven las ecuaciones hacia delante, comenzando con la primera ecuación, los cálculos son muy fáciles, ya que cada ecuación contiene sólo una incógnita a la vez.
\end{frame}
\subsection*{Sustitución hacia adelante}
\begin{frame}
\frametitle{Sustitución hacia adelante}
La solución se obtiene haciendo:
\[ \begin{split}
x_{1} &= \dfrac{c_{1}}{L_{11}} \\
x_{2} &= \dfrac{(c_{2} - L_{21} \: x_{1})}{L_{22}} \\
x_{3} &= \dfrac{(c_{3} - L_{31} \: x_{1} - L_{32} \: x_{2})}{L_{33}} \\
\ldots
\end{split} \]
Este procedimiento se conoce como \emph{sustitución hacia adelante}.
\end{frame}
\subsection*{Sustitución hacia atrás}
\begin{frame}
\frametitle{Sustitución hacia atrás}
De una manera similar la operación $U \: x = c$, se encuentra en el proceso de eliminación de Gauss, y puede resolverse fácilmente por sustitución hacia atrás, que se inicia con la última ecuación y va retrocediendo a través de las ecuaciones.
\end{frame}
\begin{frame}
\frametitle{Sustitución hacia atrás}
Las ecuaciones $L \: U \: x = b$, que están asociadas con la descomposición $L \: U$, también pueden resolverse rápidamente si las sustituimos con dos conjuntos de ecuaciones equivalentes: $L \: y = b$ y $U \: x = y$.
\end{frame}
\begin{frame}
\frametitle{Sustitución hacia atrás}
Ahora $L \: y = b$ se puede resolverse para $y$ por sustitución hacia delante, seguido de la solución de $U \: x = y$ por medio de la sustitución hacia atrás.
\end{frame}
\subsection*{Matriz identidad}
\begin{frame}
\frametitle{Operaciones con la matriz identidad}
Las ecuaciones $I \: x = c$, que se generan en la eliminación Gauss-Jordan, son equivalentes a $x = c$ (recordemos la identidad $I \: x = x$), de modo que $c$ es la solución.
\end{frame}
\subsection*{Ejercicios}
\begin{frame}
\frametitle{Ejercicio 1}
Determinar si la siguiente matriz es singular:
\[ A = 
\begin{pmatrix}
2.1 & -0.6 & 1.1 \\
3.2 & 4.7 & -0.8 \\
3.1 & -6.5 & 4.1
\end{pmatrix} \]
\end{frame}
\begin{frame}[fragile]
\frametitle{Solución al ejercicio 1}
Usando lo que hemos visto respecto a las funciones de \funcionazul{numpy.linalg}, declaramos en una variable el arreglo $\mathbf{A}$:
\begin{verbatim}
>>> A = array([[2.1, -0.6, 1.1], \
				[3.2, 4.7, -0.8], \
				[3.1, -6.5, 4.1]])
\end{verbatim}
\end{frame}
\begin{frame}[fragile]
\frametitle{Solución al ejercicio 1}
Calculamos el valor del determinante
\begin{verbatim}
>>> print (linalg.det(A))
0.0
\end{verbatim}
\end{frame}
\begin{frame}
\frametitle{Resultado}
\[ A = 
\begin{bmatrix}
2.1 & -0.6 & 1.1 \\
3.2 & 4.7 & -0.8 \\
3.1 & -6.5 & 4.1
\end{bmatrix} \]
\textcolor{red}{La matriz $A$ es singular, ya que el determinante vale cero.}
\end{frame}
\begin{frame}
\frametitle{Ejercicio 2}
Resolver la ecuación $A \: x=b$, donde
\[ A= \begin{bmatrix}
8 & -6 & 2 \\
-4 & 11 & -7 \\
4 & -7 & 6
\end{bmatrix}
\hspace{2cm}
b =\begin{bmatrix}
28 \\
-40 \\
33
\end{bmatrix} \]
\end{frame}
\subsection*{El módulo scipy.linalg}
\begin{frame}
\frametitle{El módulo \funcionazul{scipy.linalg}}
El módulo \funcionazul{scipy.linalg} extiende las funciones que hemos mencionado anteriormente de \funcionazul{numpy.linalg}.
\\
\bigskip
Incluye un conjunto de funciones para resolver problemas matriciales de una manera en particular.
\end{frame}
\begin{frame}
\frametitle{Funciones básicas en \funcionazul{scipy.linalg}}
\fontsize{12}{12}\selectfont
\begin{tabular}{l | m{7.5cm}}
Función & Descripción \\ \hline
\funcionazul{inv(a)} & Calcula la inversa de una matriz. \\ \hline
\funcionazul{solve(a, b)} & Resuelve el sistema $a \: x = b$, para una matriz $a$ cuadrada. \\ \hline
\funcionazul{solve\_banded} & Resuelve el sistema $a \: x = b$, donde $x$ es una matriz en banda. \\ \hline
\funcionazul{det(a)} & Calcula el determinante de una matriz. \\ \hline
\funcionazul{norm(a)} & Calcula la norma de una matriz.
\end{tabular}
\end{frame}
\begin{frame}[fragile]
\frametitle{Factorizaciones en \funcionazul{scipy.linalg}}
\fontsize{12}{12}\selectfont
\begin{tabular}{l | m{7.5cm}}
Función & Descripción \\ \hline
\funcionazul{lu(a)} & Factoriza $L \: U$ de una matriz $a$, devuleve la matriz pivo $P$, la matriz triangular inferior $L$ y la matriz triangular superior $U$. \\ \hline
\funcionazul{lu\_factor(a)} & Factoriza $L \: U$ de una matriz $a$, devuelve la matriz pivote y las matrices $L \: U$ superpuestas. \\ \hline
\funcionazul{lu\_solve()} & Resuelve el sistema $a \: x = b$, dada una factorización $L \: U$. \\ \hline
\end{tabular}
\end{frame}
\begin{frame}[plain, allowframebreaks,fragile]
\frametitle{Abrimos un archivo nuevo en Spyder}
Obtenemos ahora con la librería \texttt{scipy.linalg}, las matrices $L$ y $U$:
\begin{lstlisting}[caption=Código para obtener las matrices LU, style=FormattedNumber, basicstyle=\linespread{1.1}\ttfamily=\small, columns=fullflexible]
from scipy import array, linalg

A = array([[8., -6. , 2.],[-4., 11., -7.],[4., -7, 6.]])

P, L, U = linalg.lu(A)

print ('P')
print (P)

print ('L')
print (L)

print ('U')
print (U) 	
\end{lstlisting}
\end{frame}
\begin{frame}
\frametitle{¿Qué devuelve la función}
Lo que nos devuelve la función son tres arreglos: $P$, $L$ y $U$, que son las matrices pivote, triangular inferior y triangular superior, respectivamente.
\end{frame}
\begin{frame}
\frametitle{Resultado de la factorización}
La descomposición $L \: U$ de la matriz de coeficientes $A$ es:
\[ A = LU = \begin{bmatrix}
 1. &   0. &   0. \\
 -0.5 & 1. &  0. \\
 0.5 & -0.5 &  1
\end{bmatrix}
\begin{bmatrix}
 8. & -6. &  2. \\
  0. &  8. & 6. \\
  0. &  0. &  2.
\end{bmatrix} \]
\end{frame}
\subsection{Operación con matrices}
\begin{frame}[fragile]
\frametitle{Recuperando la matriz inicial $A$}
Para verificar que efectivamente el producto de las matrices $L$ y $U$ nos regresa la matriz $A$, basta con que realicemos el producto de matrices:
\end{frame}
\begin{frame}[fragile]
\frametitle{Recuperando la matriz inicial $A$}
Si usamos el operador multiplicación:
\begin{verbatim}
>>> print (L*U)
array([[  0. ,  -6. ,   4. ],
       [ -0. ,   8. , -12. ],
       [  0. ,  -0.5,   4. ]])

\end{verbatim}
\pause
Vemos que el resultado no es la matriz inicial $A$, ¿por qué?
\end{frame}
\begin{frame}
\frametitle{Una operación que no devuelve lo esperado}
Lo que obtenemos es una matriz que es el producto \enquote{entrada} por \enquote{entrada} de las matrices $L$ y $U$, por lo que no es nuestra matriz inicial $A$.
\end{frame}
\begin{frame}
\frametitle{Una operación que no devuelve lo esperado}
La manera de recuperar la matriz $A$, es mediante el correcto uso del producto de dos arreglos, para esto debemos de utilizar la función \funcionazul{dot}, recordemos que se puede usar hasta de tres maneras distintas:
\end{frame}
\begin{frame}[fragile]
\frametitle{\funcionazul{dot} con escalares y matrices}
\setbeamercolor{item projected}{bg=red!70!black,fg=white}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\item Cuando multiplicamos un escalar por un escalar, nos devuelve un escalar. \\
\begin{verbatim}
>>> dot(3, 4)
>>>12
\end{verbatim}
\seti
\end{enumerate}
\end{frame}
\begin{frame}[fragile]
\frametitle{\funcionazul{dot} con escalares y matrices}
\setbeamercolor{item projected}{bg=red!70!black,fg=white}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\conti
\item Cuando multiplicamos un escalar por un arreglo, nos devuelve un arreglo.\\
\begin{verbatim}
>>> dot(-1, L)
>>> array([[-1. ,  0. ,  0. ],
       [ 0.5, -1. ,  0. ],
       [-0.5,  0.5, -1. ]])
\end{verbatim}
\seti
\end{enumerate}
\end{frame}
\begin{frame}[fragile]
\frametitle{\funcionazul{dot} con escalares y matrices}
\setbeamercolor{item projected}{bg=red!70!black,fg=white}
\setbeamertemplate{enumerate items}[circle]
\begin{enumerate}[<+->]
\conti
\item Cuando multiplicamos un arreglo por un arreglo, nos devuelve un arreglo. \\
\begin{verbatim}
>>> dot(L, U)
\end{verbatim}
\end{enumerate}
\end{frame}
\begin{frame}[fragile]
\frametitle{Uso de la función \azulfuerte{\texttt{dot}}}
Entonces la manera en que debemos de usar la función \texttt{dot} es la siguiente:
\begin{verbatim}
>>> dot(L,U)
array([[  8.,  -6.,   2.],
       [ -4.,  11.,  -7.],
       [  4.,  -7.,   6.]])
\end{verbatim}
Que corresponde a la matriz inicial $A$.
\end{frame}
\begin{frame}
\frametitle{Solución mediante sustituciones}
Una vez conocidas las matrices $L$ y $U$, podemos realizar los procedimientos de sustutición hacia adelante para $L$, y luego la sustitución hacia atrás para $U$, así conoceremos la solución del problema.
\end{frame}
\begin{frame}[fragile]
\frametitle{Solución para $L$}
Resolvemos primero $L \: y=b$ con sustitución hacia adelante:
\[\begin{split}
 y_{1} =& 28 \\
-\dfrac{y_{1}}{2} + y_{2} =& -40 \hspace{0.5cm} \rightarrow \hspace{0.5cm} y_{2} = -40+ \dfrac{y_{1}}{2} = -26 \\
\dfrac{y_{1}}{2} -\dfrac{y_{2}}{2} + y_{3} =& 33 \hspace{0.5cm} \rightarrow \hspace{0.5cm} y_{3} = 33 + \dfrac{y_{2}}{2}+ \dfrac{y_{1}}{2} = 6
\end{split} \]
\end{frame}
\begin{frame}[fragile]
\frametitle{Solución para $U$}
La solución $x$ ahora se obtiene de $Ux=y$ por sustitución hacia atrás:
\[ \begin{split}
2x_{3} =& y_{3} \hspace{0.5cm} \rightarrow \hspace{0.5cm} x_{3} = y_{3}/2 = 3 \\
8x_{2} - 6x_{3} =& y_{2} \hspace{0.5cm} \rightarrow \hspace{0.5cm} x_{2} = \dfrac{y_{2} + 6 x_{3}}{8} = -1 \\
8x_{1} - 6x_{2} + 2 x_{3} =& y_{1} \hspace{0.5cm} \rightarrow \hspace{0.5cm} x_{1} = \dfrac{y_{1} + 6 x_{2} - 2x_{3}}{8}=2
\end{split} \]
\visible<2->{Por tanto la solución es $x=[2, -1, 3]^{T}$}
\end{frame}
\end{document}